{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Just take all width for viz\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .master('local[*]') \\\n",
    "    .config(\"spark.driver.memory\", \"10g\") \\\n",
    "    .appName(\"steam-analysis-eda\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = os.path.join(os.path.dirname(os.path.realpath(\"\")), \"data/\")\n",
    "\n",
    "df = spark.read.parquet(\"file://\" + dataset_path + \"steam-dataset/steam_analysis.Games_Daily\")\n",
    "\n",
    "publishers = spark.sql(\n",
    "    'select appid from parquet.`{}`'.format(\"file://\" + dataset_path + \"extracts/steam-dataset_games_28-12_5\")\n",
    ")\n",
    "\n",
    "df = df \\\n",
    "    .join(publishers, on = 'appid') \\\n",
    "    .groupBy('appid') \\\n",
    "    .agg(F.size(F.collect_list('steamid')).alias('n_players')) \\\n",
    "    .sort(F.col('n_players').desc())\n",
    "\n",
    "revsum_df = spark \\\n",
    "    .sql(\n",
    "        \"\"\"SELECT\n",
    "        appid,\n",
    "        total_reviews\n",
    "        FROM parquet.`{}`\"\"\".format(\"file://\" + dataset_path + \"extracts/steam-reviews.parquet\"))\n",
    "\n",
    "genres_df = spark.sql(\n",
    "    'select appid, Explode(genres) AS genres from parquet.`{}`'.format(\"file://\" + dataset_path + \"extracts/steam-dataset_games_28-12_5\")\n",
    ")\n",
    "\n",
    "joined_df = genres_df.join(revsum_df, on = ['appid'])\n",
    "\n",
    "joined_df = joined_df \\\n",
    "    .groupBy('appid') \\\n",
    "    .agg(F.collect_set('total_reviews').alias('total_reviews')) \\\n",
    "    .select('appid', F.explode('total_reviews').alias('total_reviews')) \\\n",
    "    .join(genres_df, on = ['appid']) \\\n",
    "    .join(df, on = ['appid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler, QuantileDiscretizer, StringIndexer, OneHotEncoder\n",
    "from pyspark.ml.stat import ChiSquareTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------+----------+---------+--------------+------------------+----------+---------------+---------------+----------+\n",
      "| appid|total_reviews|    genres|n_players|n_players_bins|total_reviews_bins|genreIndex|     genres_vec|boxleiter_value|  features|\n",
      "+------+-------------+----------+---------+--------------+------------------+----------+---------------+---------------+----------+\n",
      "|301190|          267|    Casual|      880|           0.0|               1.0|       5.0| (16,[5],[1.0])|          13350| [5.0,1.0]|\n",
      "|301190|          267|     Indie|      880|           0.0|               1.0|       0.0| (16,[0],[1.0])|          13350| [0.0,1.0]|\n",
      "|301190|          267|    Action|      880|           0.0|               1.0|       1.0| (16,[1],[1.0])|          13350| [1.0,1.0]|\n",
      "|253470|           91|    Racing|     1466|           1.0|               0.0|       9.0| (16,[9],[1.0])|           4550| [9.0,0.0]|\n",
      "|253470|           91|     Indie|     1466|           1.0|               0.0|       0.0| (16,[0],[1.0])|           4550| (2,[],[])|\n",
      "|253470|           91|Simulation|     1466|           1.0|               0.0|       7.0| (16,[7],[1.0])|           4550| [7.0,0.0]|\n",
      "|214130|           96|     Indie|      802|           0.0|               0.0|       0.0| (16,[0],[1.0])|           4800| (2,[],[])|\n",
      "|214130|           96|Simulation|      802|           0.0|               0.0|       7.0| (16,[7],[1.0])|           4800| [7.0,0.0]|\n",
      "|204960|          207|    Casual|     1883|           1.0|               1.0|       5.0| (16,[5],[1.0])|          10350| [5.0,1.0]|\n",
      "|204960|          207|     Indie|     1883|           1.0|               1.0|       0.0| (16,[0],[1.0])|          10350| [0.0,1.0]|\n",
      "|235980|          110|    Casual|      573|           0.0|               0.0|       5.0| (16,[5],[1.0])|           5500| [5.0,0.0]|\n",
      "|235980|          110|     Indie|      573|           0.0|               0.0|       0.0| (16,[0],[1.0])|           5500| (2,[],[])|\n",
      "|296910|          350|    Casual|     2468|           1.0|               1.0|       5.0| (16,[5],[1.0])|          17500| [5.0,1.0]|\n",
      "|296910|          350|     Indie|     2468|           1.0|               1.0|       0.0| (16,[0],[1.0])|          17500| [0.0,1.0]|\n",
      "|296910|          350|    Action|     2468|           1.0|               1.0|       1.0| (16,[1],[1.0])|          17500| [1.0,1.0]|\n",
      "|212780|          119|     Indie|     2316|           1.0|               0.0|       0.0| (16,[0],[1.0])|           5950| (2,[],[])|\n",
      "|212780|          119|    Sports|     2316|           1.0|               0.0|      10.0|(16,[10],[1.0])|           5950|[10.0,0.0]|\n",
      "|212780|          119|Simulation|     2316|           1.0|               0.0|       7.0| (16,[7],[1.0])|           5950| [7.0,0.0]|\n",
      "|266230|          341|     Indie|     2075|           1.0|               1.0|       0.0| (16,[0],[1.0])|          17050| [0.0,1.0]|\n",
      "|266230|          341|       RPG|     2075|           1.0|               1.0|       4.0| (16,[4],[1.0])|          17050| [4.0,1.0]|\n",
      "+------+-------------+----------+---------+--------------+------------------+----------+---------------+---------------+----------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+-------+------------------+------------------+--------------+------------------+------------------+------------------+------------------+------------------+\n",
      "|summary|             appid|     total_reviews|        genres|         n_players|    n_players_bins|total_reviews_bins|        genreIndex|   boxleiter_value|\n",
      "+-------+------------------+------------------+--------------+------------------+------------------+------------------+------------------+------------------+\n",
      "|  count|               248|               248|           248|               248|               248|               248|               248|               248|\n",
      "|   mean|249169.03225806452|314.14112903225805|          null|1981.3629032258063|             0.875|0.9354838709677419| 2.975806451612903|15707.056451612903|\n",
      "| stddev| 44985.40588212494|143.84007736444667|          null|1282.0615094143893|0.7230306213102088|0.6329921935914438|3.0274418582860245| 7192.003868222333|\n",
      "|    min|              9940|                87|        Action|               373|               0.0|               0.0|               0.0|              4350|\n",
      "|    max|            317510|               608|Web Publishing|              5003|               2.0|               2.0|              16.0|             30400|\n",
      "+-------+------------------+------------------+--------------+------------------+------------------+------------------+------------------+------------------+\n",
      "\n",
      "\n",
      "root\n",
      " |-- appid: long (nullable = true)\n",
      " |-- Education: integer (nullable = false)\n",
      " |-- Massively Multiplayer: integer (nullable = false)\n",
      " |-- Adventure: integer (nullable = false)\n",
      " |-- Sports: integer (nullable = false)\n",
      " |-- Racing: integer (nullable = false)\n",
      " |-- Software Training: integer (nullable = false)\n",
      " |-- Web Publishing: integer (nullable = false)\n",
      " |-- Utilities: integer (nullable = false)\n",
      " |-- Early Access: integer (nullable = false)\n",
      " |-- Casual: integer (nullable = false)\n",
      " |-- Action: integer (nullable = false)\n",
      " |-- Strategy: integer (nullable = false)\n",
      " |-- Indie: integer (nullable = false)\n",
      " |-- Free to Play: integer (nullable = false)\n",
      " |-- RPG: integer (nullable = false)\n",
      " |-- Simulation: integer (nullable = false)\n",
      " |-- total_reviews: long (nullable = false)\n",
      " |-- genres: string (nullable = true)\n",
      " |-- n_players: integer (nullable = true)\n",
      " |-- n_players_bins: double (nullable = true)\n",
      " |-- total_reviews_bins: double (nullable = false)\n",
      " |-- genreIndex: double (nullable = false)\n",
      " |-- genres_vec: vector (nullable = true)\n",
      " |-- boxleiter_value: long (nullable = false)\n",
      " |-- features: vector (nullable = true)\n",
      "\n",
      "pValues: [2.843954788334102e-07,0.0]\n",
      "degreesOfFreedom: [30, 4]\n",
      "statistics: [85.75827664173863,103.76499083084349]\n"
     ]
    }
   ],
   "source": [
    "# Discretize n_players to get classification problem (actually ordinal classification)\n",
    "discretizer = QuantileDiscretizer(numBuckets=5, inputCol=\"n_players\", outputCol=\"n_players_bins\")\n",
    "result = discretizer.fit(joined_df).transform(joined_df)\n",
    "\n",
    "# Discretize total_reviews for chi² => TO-DO : replace by pearson corr\n",
    "discretizer = QuantileDiscretizer(numBuckets=5, inputCol=\"total_reviews\", outputCol=\"total_reviews_bins\")\n",
    "result = discretizer.fit(result).transform(result)\n",
    "\n",
    "# Encode genres to numerical type\n",
    "indexer = StringIndexer(inputCol=\"genres\", outputCol=\"genreIndex\")\n",
    "result = indexer.fit(result).transform(result)\n",
    "\n",
    "encoder = OneHotEncoder(\n",
    "    inputCols=[\"genreIndex\"],\n",
    "    outputCols=[\"genres_vec\"]\n",
    ")\n",
    "model = encoder.fit(result)\n",
    "result = model.transform(result)\n",
    "\n",
    "result = result.withColumn('boxleiter_value', F.col('total_reviews') * 50)\n",
    "\n",
    "# Create vectors for ml compat\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=[\"genreIndex\", \"total_reviews_bins\"],\n",
    "    outputCol=\"features\"\n",
    ")\n",
    "result = assembler.transform(result)\n",
    "\n",
    "##############################################\n",
    "\n",
    "quantiles = result \\\n",
    "    .approxQuantile(['total_reviews', 'n_players'], [0.1, 0.5, 0.8], 0.01)\n",
    "\n",
    "result = result \\\n",
    "    .filter(F.col('total_reviews') > quantiles[0][0]).filter(F.col('total_reviews') < quantiles[0][1]) \\\n",
    "    .filter(F.col('n_players') > quantiles[1][0]).filter(F.col('n_players') < quantiles[1][1])\n",
    "\n",
    "result.show()\n",
    "result.describe().show()\n",
    "print()\n",
    "\n",
    "##############################################\n",
    "# Encode genreIndex as dummy\n",
    "distinct_genres = result.select('genres').distinct().rdd.map(lambda x: x.genres).collect()\n",
    "\n",
    "expr = [F.when(F.col(\"genres\") == genre, 1).otherwise(0).alias(genre) for i, genre in enumerate(distinct_genres)]\n",
    "\n",
    "df = result.select(\"appid\", *expr)\n",
    "result = df.join(result, on = ['appid'])\n",
    "result.printSchema()\n",
    "\n",
    "##############################################\n",
    "\n",
    "# Perform Chi-Square Test\n",
    "r = ChiSquareTest.test(result, \"features\", \"n_players_bins\").head()\n",
    "print(\"pValues: \" + str(r.pValues))\n",
    "print(\"degreesOfFreedom: \" + str(r.degreesOfFreedom))\n",
    "print(\"statistics: \" + str(r.statistics))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Class weighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from itertools import chain\n",
    "\n",
    "distinct_labels = result.select('n_players_bins').groupBy('n_players_bins').count().collect()\n",
    "\n",
    "unique_y = [x[\"n_players_bins\"] for x in distinct_labels]\n",
    "total_y = sum([x[\"count\"] for x in distinct_labels])\n",
    "unique_y_count = len(distinct_labels)\n",
    "bin_count = [x[\"count\"] for x in distinct_labels]\n",
    "\n",
    "class_weights_spark = {i: ii for i, ii in zip(unique_y, total_y / (unique_y_count * np.array(bin_count)))}\n",
    "mapping_expr = F.create_map([F.lit(x) for x in chain(*class_weights_spark.items())])\n",
    "\n",
    "result = result.withColumn(\"weight\", mapping_expr[F.col(\"n_players_bins\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generic train function with grid search and cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse : 1251.8620652831128\n"
     ]
    }
   ],
   "source": [
    "def train_model(df, model, params_grid, labelCol = \"label\"):\n",
    "    train, test = df.randomSplit([0.66, 0.34])\n",
    "\n",
    "    evaluator = RegressionEvaluator(\n",
    "        predictionCol='prediction', \n",
    "        labelCol='n_players', \n",
    "        metricName='rmse'\n",
    "    )\n",
    "\n",
    "    cv = CrossValidator(\n",
    "            estimator=model, \n",
    "            estimatorParamMaps=params_grid, \n",
    "            evaluator=evaluator,\n",
    "            parallelism=2\n",
    "    )\n",
    "    cvModel = cv.fit(train)\n",
    "    print(evaluator.getMetricName(), ':', cvModel.avgMetrics[0])\n",
    "    return cvModel\n",
    "\n",
    "general_linear_model = train_model(result, model, grid, labelCol = \"n_players\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.evaluation import RegressionEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for genre = Education \n",
      "\n",
      "Not enough data ! (N = 4) \n",
      "\n",
      "Training model for genre = Massively Multiplayer \n",
      "\n",
      "Not enough data ! (N = 10) \n",
      "\n",
      "Training model for genre = Adventure \n",
      "\n",
      "rmse : 1403.7791074424806\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'LinearRegression' object has no attribute 'bestModel'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-b7411a203240>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;31m# Train model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mcvModel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabelCol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"n_players\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0mcoef\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mintercept\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbestModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoefficients\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbestModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintercept\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"total_reviews\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"genreIndex\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoef\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Intercept:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mintercept\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'LinearRegression' object has no attribute 'bestModel'"
     ]
    }
   ],
   "source": [
    "distinct_genres = result.select('genres').distinct().rdd.map(lambda x: x.genres).collect()\n",
    "\n",
    "# Define model and grid search params\n",
    "model = LinearRegression(\n",
    "    featuresCol= \"features\",\n",
    "    labelCol= \"n_players\",\n",
    "    weightCol = \"weight\"\n",
    ")\n",
    "grid = ParamGridBuilder().addGrid(model.maxIter, [1, 5, 10]).build()\n",
    "\n",
    "# Store fitted model for later comparison\n",
    "models = {}\n",
    "for genre in distinct_genres:\n",
    "    \n",
    "    print('Training model for genre = {} \\n'.format(genre))\n",
    "    # Filter data\n",
    "    df = result.filter(F.col('genres') == genre)\n",
    "    \n",
    "    # Check count for cross validation\n",
    "    count = df.count()\n",
    "    \n",
    "    if count > 20:\n",
    "        # get features\n",
    "        df = df.drop('features')\n",
    "        assembler = VectorAssembler(\n",
    "            inputCols=[\"total_reviews\", \"genreIndex\"],\n",
    "            outputCol=\"features\"\n",
    "        )\n",
    "        df = assembler.transform(df)\n",
    "\n",
    "        # Train model\n",
    "        cvModel = train_model(df, model, grid, labelCol = \"n_players\")\n",
    "        coef, intercept = cvModel.bestModel.coefficients, cvModel.bestModel.intercept\n",
    "        print(dict(zip([\"total_reviews\", \"genreIndex\"], coef)))\n",
    "        print('Intercept:', intercept)\n",
    "        print(\"\\n\")\n",
    "        \n",
    "        models[genre] = cvModel\n",
    "    else:\n",
    "        print('Not enough data ! (N = {}) \\n'.format(count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking at coefficients\n",
    "\n",
    "coefficients = []\n",
    "for genre, model in models.items() :\n",
    "    coef = model.bestModel.coefficients\n",
    "    intercept = model.bestModel.intercept\n",
    "\n",
    "    print('Genre: {}'.format(genre))\n",
    "    print(dict(zip([\"total_reviews\", \"genreIndex\"], coef)))\n",
    "    print('Intercept:', intercept)\n",
    "    \n",
    "    # Get total_reviews coefficients\n",
    "    # Genre is only != 0 if genre = early access\n",
    "    coefficients.append((genre, coef[0]))\n",
    "    \n",
    "coefficients = sorted(coefficients, key = lambda x: x[1], reverse = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(\n",
    "    go.Bar(\n",
    "        x=list(x[0] for x in coefficients), \n",
    "        y=list(x[1] for x in coefficients)\n",
    "    )\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Partial Dependency Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from itertools import chain\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# Disable SettingCopyWarning\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.inspection import plot_partial_dependence, partial_dependence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pdp(model, X, feature, target=False, return_pd=False, y_pct=True, figsize=(10,9), norm_hist=True, dec=.5, xticks = None):\n",
    "    # Get partial dependence\n",
    "    pardep = partial_dependence(model, X, [feature], method = 'brute', kind = 'average')\n",
    "    \n",
    "    # Get min & max values\n",
    "    xmin = pardep[\"values\"][0].min()\n",
    "    xmax = pardep[\"values\"][0].max()\n",
    "    ymin = pardep[\"average\"][0].min()\n",
    "    ymax = pardep[\"average\"][0].max()\n",
    "    \n",
    "    # Create figure\n",
    "    fig, ax1 = plt.subplots(figsize=figsize)\n",
    "    ax1.grid(alpha=.5, linewidth=1)\n",
    "    \n",
    "    # Plot partial dependence\n",
    "    color = 'tab:blue'\n",
    "    ax1.plot(pardep[\"values\"][0], pardep[\"average\"][0], color=color)\n",
    "    ax1.tick_params(axis='y', labelcolor=color)\n",
    "    if not xticks:\n",
    "        ax1.set_xlabel(feature, fontsize=14)\n",
    "    else:\n",
    "        plt.xticks(ticks = range(len(xticks)) , labels = xticks, rotation = 'vertical')\n",
    "    \n",
    "    tar_ylabel = ': {}'.format(target) if target else ''\n",
    "    ax1.set_ylabel('Partial Dependence{}'.format(tar_ylabel), color=color, fontsize=14)\n",
    "    \n",
    "    tar_title = target if target else 'Target Variable'\n",
    "    ax1.set_title('Relationship Between {} and {}'.format(feature, tar_title), fontsize=16)\n",
    "    \n",
    "    if y_pct and ymin>=0 and ymax<=1:\n",
    "        # Display yticks on ax1 as percentages\n",
    "        fig.canvas.draw()\n",
    "        labels = [item.get_text() for item in ax1.get_yticklabels()]\n",
    "        labels = [int(np.float(label)*100) for label in labels]\n",
    "        labels = ['{}%'.format(label) for label in labels]\n",
    "        ax1.set_yticklabels(labels)\n",
    "    \n",
    "    # Plot line for decision boundary\n",
    "    ax1.hlines(dec, xmin=xmin, xmax=xmax, color='black', linewidth=2, linestyle='--', label='Decision Boundary')\n",
    "    ax1.legend()\n",
    "\n",
    "    ax2 = ax1.twinx()\n",
    "    color = 'tab:red'\n",
    "    ax2.hist(X[feature], bins=80, range=(xmin, xmax), alpha=.25, color=color, density=norm_hist)\n",
    "    ax2.tick_params(axis='y', labelcolor=color)\n",
    "    ax2.set_ylabel('Distribution', color=color, fontsize=14)\n",
    "    \n",
    "    if y_pct and norm_hist:\n",
    "        # Display yticks on ax2 as percentages\n",
    "        fig.canvas.draw()\n",
    "        labels = [item.get_text() for item in ax2.get_yticklabels()]\n",
    "        labels = [int(np.float(label)*100) for label in labels]\n",
    "        labels = ['{}%'.format(label) for label in labels]\n",
    "        ax2.set_yticklabels(labels)\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "    if return_pd:\n",
    "        return pardep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xticks = pd_df['genres'].unique().tolist()\n",
    "plot_pdp(clf, X, 'genreIndex', target='n_players', xticks = xticks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distinct_labels = result.select('n_players_bins').groupBy('n_players_bins').count().collect()\n",
    "\n",
    "unique_y = [x[\"n_players_bins\"] for x in distinct_labels]\n",
    "total_y = sum([x[\"count\"] for x in distinct_labels])\n",
    "unique_y_count = len(distinct_labels)\n",
    "bin_count = [x[\"count\"] for x in distinct_labels]\n",
    "\n",
    "class_weights_spark = {i: ii for i, ii in zip(unique_y, total_y / (unique_y_count * np.array(bin_count)))}\n",
    "mapping_expr = F.create_map([F.lit(x) for x in chain(*class_weights_spark.items())])\n",
    "\n",
    "result = result.withColumn(\"weight\", mapping_expr[F.col(\"n_players_bins\")])\n",
    "\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_df = result \\\n",
    "    .select('genreIndex', 'genres', 'total_reviews', 'n_players') \\\n",
    "    .toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = pd_df[['genreIndex', 'total_reviews']], pd_df['n_players']\n",
    "clf = GradientBoostingRegressor(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=0).fit(X, y)\n",
    "features = [0, 1, (0, 1)]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 5))\n",
    "plot_partial_dependence(clf, X, features, kind = 'average', ax = ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking pdp from one class VS the others\n",
    "\n",
    "distinct_genres = pd_df.genres.unique()\n",
    "\n",
    "for target_class in distinct_genres:\n",
    "\n",
    "    print('TARGET_CLASS:', target_class)\n",
    "    early_df = pd_df.loc[pd_df.genres == target_class]\n",
    "    early_df['genreIndex'] = 1\n",
    "    other_df = pd_df.loc[pd_df.genres != target_class]\n",
    "    other_df['genres'] = \"Other\"\n",
    "    other_df['genreIndex'] = 0\n",
    "\n",
    "    df = pd.concat([early_df, other_df])\n",
    "    X, y = df[['genreIndex', 'total_reviews']], df['n_players']\n",
    "\n",
    "    clf = GradientBoostingRegressor(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=0).fit(X, y)\n",
    "\n",
    "    xticks = df['genres'].unique().tolist()\n",
    "    plot_pdp(clf, X, 'genreIndex', target='n_players', xticks = xticks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kernel Density Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result \\\n",
    "    .select('total_reviews', 'n_players') \\\n",
    "    .toPandas().plot.kde(figsize=(10,5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "steam-analysis",
   "language": "python",
   "name": "steam-analysis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
